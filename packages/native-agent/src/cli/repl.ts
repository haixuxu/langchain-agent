import * as readline from "readline";
import { NativeAgent } from "../native-agent.js";
import { MCPConfig, REPLContext, handleCommand } from "@langchain-agent/core";
import { NativeTool } from "../tool-converter.js";

/**
 * å¯åŠ¨äº¤äº’å¼REPLï¼ˆåŸç”Ÿ Agent ç‰ˆæœ¬ï¼‰
 */
export async function startNativeREPL(
  agent: NativeAgent,
  config: MCPConfig,
  clients?: any[],
  tools?: NativeTool[]
): Promise<void> {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
    prompt: "\nğŸ¤– > ",
  });

  const context: REPLContext = {
    agent: agent as any, // å…¼å®¹ REPLContext ç±»å‹
    config,
    clients,
    tools: tools as any,
  };

  // è®¾ç½® readline æ¥å£åˆ° agentï¼Œä»¥ä¾¿ç¡®è®¤ç®¡ç†å™¨å¯ä»¥è¯¢é—®ç”¨æˆ·
  agent.setReadlineInterface(rl);

  console.log("\n" + "=".repeat(50));
  console.log("ğŸ¤– Native Agent with MCP Support (ä¸ä½¿ç”¨ LangChain)");
  console.log("=".repeat(50));
  console.log('è¾“å…¥ "/help" æŸ¥çœ‹å¯ç”¨å‘½ä»¤');
  console.log('ç›´æ¥è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯\n');
  console.log('æç¤º: å·¥å…·è°ƒç”¨å‰ä¼šè¯·æ±‚ç¡®è®¤ï¼Œå¯ä»¥ä½¿ç”¨ y/n/all/stop å‘½ä»¤\n');

  rl.prompt();

  rl.on("line", async (input) => {
    const trimmed = input.trim();

    if (!trimmed) {
      rl.prompt();
      return;
    }

    // æ£€æŸ¥æ˜¯å¦ä¸ºå‘½ä»¤
    if (trimmed.startsWith("/")) {
      await handleCommand(trimmed, context);
      rl.prompt();
      return;
    }

    // å¤„ç†ç”¨æˆ·è¾“å…¥
    try {
      console.log("\nğŸ¤” æ€è€ƒä¸­...\n");

      // Prefer streaming output first â€” stream is non-blocking and shows increments
      try {
        let hasContent = false;
        let currentToolCalls: any[] = [];
        let toolCallsShown = false;

        for await (const chunk of agent.stream(trimmed)) {
          if (chunk.type === "content") {
            process.stdout.write(chunk.content);
            hasContent = true;
          } else if (chunk.type === "tool_call_start") {
            // å·¥å…·è°ƒç”¨å¼€å§‹ï¼ˆç¡®è®¤ç®¡ç†å™¨ä¼šå¤„ç†ç¡®è®¤æç¤ºï¼‰
            currentToolCalls.push(chunk.tool_call);
          } else if (chunk.type === "tool_calls") {
            currentToolCalls = chunk.tool_calls;
          } else if (chunk.type === "tool_result") {
            // å·¥å…·ç»“æœï¼ˆç¡®è®¤ç®¡ç†å™¨å·²æ˜¾ç¤ºï¼Œè¿™é‡Œä¸å†é‡å¤æ˜¾ç¤ºï¼‰
            if (chunk.confirmed === false) {
              console.log(`\nâš ï¸  å·¥å…·è°ƒç”¨è¢«å–æ¶ˆæˆ–æœªç¡®è®¤\n`);
            }
          } else if (chunk.type === "tool_error") {
            console.log(`\nâŒ å·¥å…·é”™è¯¯: ${chunk.error}\n`);
          } else if (chunk.type === "stopped") {
            console.log(`\n\n${chunk.message}`);
            hasContent = true; // æ ‡è®°ä¸ºæœ‰å†…å®¹ï¼Œé¿å…æ˜¾ç¤º"æ— å“åº”"
          }
        }

        if (!hasContent && !toolCallsShown) {
          // If stream produced no visible output, fall back to non-streaming invoke
          try {
            const result = await agent.invoke(trimmed);
            if (result.output) {
              console.log("\n" + result.output);
            } else {
              console.log("ï¼ˆæ— å“åº”å†…å®¹ï¼‰");
            }
          } catch (invokeError) {
            // both stream and invoke failed
            throw invokeError;
          }
        }
      } catch (streamError) {
        // If streaming failed (older OpenAI SDK, network), fallback to invoke
        console.warn("stream å¤±è´¥ï¼Œé€€å›åˆ° invoke æ–¹æ³•ï¼š", streamError instanceof Error ? streamError.message : streamError);
        try {
          const result = await agent.invoke(trimmed);
          if (result.output) {
            console.log("\n" + result.output);
          }
        } catch (invokeError) {
          throw invokeError;
        }
      }

      console.log("\n");
    } catch (error) {
      console.error(
        "\nâŒ é”™è¯¯:",
        error instanceof Error ? error.message : error
      );
      if (process.env.DEBUG === "true") {
        console.error(error);
      }
    }

    rl.prompt();
  });

  rl.on("close", () => {
    console.log("\n\nå†è§ï¼");
    process.exit(0);
  });
}

